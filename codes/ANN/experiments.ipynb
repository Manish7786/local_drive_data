{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05248b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88d2b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the dataset\n",
    "df = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2073033",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess the data\n",
    "### Drop irrelevent columns\n",
    "data = df.drop(columns=['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef1a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encode categorical feature\n",
    "label_encoder_gender = LabelEncoder()\n",
    "data['Gender'] = label_encoder_gender.fit_transform(data['Gender'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b1e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One Hot Encode 'geographical' column\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot_encoder_geo = OneHotEncoder()\n",
    "geo_encoder = onehot_encoder_geo.fit_transform(data[['Geography']])\n",
    "geo_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7d16ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoder_geo.get_feature_names_out(['Geography'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20606e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_encoded_df = pd.DataFrame(geo_encoder.toarray(), columns=onehot_encoder_geo.get_feature_names_out(['Geography']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a3903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0aa418",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine one hot encoded columns with the original data\n",
    "data = pd.concat([data.drop(['Geography'], axis=1), geo_encoded_df], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171552cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the encoder and scaler\n",
    "with open('label_encoder_gender.pkl', 'wb') as file:\n",
    "    pickle.dump(label_encoder_gender, file)\n",
    "\n",
    "with open('onehot_encoder_geo.pkl', 'wb') as file:\n",
    "    pickle.dump(onehot_encoder_geo, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256828db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divide the dataset into dependent and independent features\n",
    "X = data.drop('Exited', axis=1)\n",
    "y = data['Exited']\n",
    "\n",
    "## Split the data in training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "## Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cfb092",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74dd7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0277dc",
   "metadata": {},
   "source": [
    "## ANN IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0941215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005918d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train.shape[1],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551bb8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build our ANN model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),   ## HL1 connected with input layer\n",
    "    Dense(32, activation='relu'),  ## HL2\n",
    "    Dense(1, activation='sigmoid')  ## Output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ba52cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca35e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "opt = tensorflow.keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss = tensorflow.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d33134",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compile the model\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e436f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup the tensorboard\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorflow_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b613a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup Early Stopping\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1baa1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train, validation_data=(X_test, y_test), epochs=100,\n",
    "    callbacks=[tensorflow_callback, early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c3e538",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a401f801",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Tensorboard Extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9419514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62025e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
