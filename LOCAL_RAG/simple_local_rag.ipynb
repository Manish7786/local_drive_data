{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import PDF Document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File human-nutrition-text.pdf exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Get PDF Document Path\n",
    "pdf_path = \"human-nutrition-text.pdf\"\n",
    "\n",
    "# Download PDF\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(\"[INFO] File doesn't exist, downloading...\")\n",
    "\n",
    "    # Enter URL of the pdf\n",
    "    url = \"https://pressbooks.oer.hawaii.edu/humannutrition2/open/download?type=pdf\"\n",
    "\n",
    "    # The local file name to save the downloaded file\n",
    "    filename = pdf_path\n",
    "\n",
    "    # Send a GET request to url\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Open the file and save it\n",
    "        with open(filename, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"[INFO] The file has been downloaded and saved as {filename}\")\n",
    "    else:\n",
    "        print(f\"[INFO] Failed to downlaod the file. Status code: {response.status_code}\")\n",
    "\n",
    "\n",
    "else:\n",
    "    print(f\"File {pdf_path} exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1208it [00:02, 499.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'page_number': -41,\n",
       "  'page_char_count': 29,\n",
       "  'page_word_count': 4,\n",
       "  'page_sentence_count_raw': 1,\n",
       "  'page_token_count': 7.25,\n",
       "  'text': 'Human Nutrition: 2020 Edition'},\n",
       " {'page_number': -40,\n",
       "  'page_char_count': 0,\n",
       "  'page_word_count': 1,\n",
       "  'page_sentence_count_raw': 1,\n",
       "  'page_token_count': 0.0,\n",
       "  'text': ''}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def text_formatter(text:str) -> str:\n",
    "    \"\"\"Performs minor formatting on text.\"\"\"\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
    "\n",
    "    # Potentially more text formatting functions can go here.\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    pages_and_texts = []\n",
    "    for page_number, page in tqdm(enumerate(doc)):\n",
    "        text = page.get_text()\n",
    "        text = text_formatter(text=text)\n",
    "        pages_and_texts.append({\"page_number\": page_number - 41,\n",
    "                                \"page_char_count\": len(text),\n",
    "                                \"page_word_count\": len(text.split(\" \")),\n",
    "                                \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "                                \"page_token_count\": len(text) / 4, # 1 token = ~4 characters\n",
    "                                \"text\": text})\n",
    "        \n",
    "    return pages_and_texts\n",
    "\n",
    "pages_and_texts = open_and_read_pdf(pdf_path=pdf_path)\n",
    "pages_and_texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 76,\n",
       "  'page_char_count': 1222,\n",
       "  'page_word_count': 205,\n",
       "  'page_sentence_count_raw': 10,\n",
       "  'page_token_count': 305.5,\n",
       "  'text': '“Histology  Small  Intestines” by  OpenStax  College / CC  BY 3.0  area to maximize nutrient absorption. The surface area is increased  by folds, villi, and microvilli. Digested nutrients are absorbed into  either capillaries or lymphatic vessels contained within each  microvillus.  The small intestine is perfectly structured for maximizing  nutrient absorption. Its surface area is greater than 200 square  meters, which is about the size of a tennis court. The large surface  area is due to the multiple levels of folding. The internal tissue  of the small intestine is covered in villi, which are tiny finger-like  projections that are covered with even smaller projections, called  microvilli (Figure 2.8 “Structure of the Small Intestine”). The  digested nutrients pass through the absorptive cells of the intestine  via diffusion or special transport proteins. Amino acids, short fatty  acids, and monosaccharides (sugars) are transported from the  intestinal cells into capillaries, but the larger fatty acids, fat-soluble  vitamins, and other lipids are transported first through lymphatic  vessels, which soon meet up with blood vessels.  Figure 2.8 Structure of the Small Intestine  76  |  The Digestive System'},\n",
       " {'page_number': 443,\n",
       "  'page_char_count': 1822,\n",
       "  'page_word_count': 308,\n",
       "  'page_sentence_count_raw': 17,\n",
       "  'page_token_count': 455.5,\n",
       "  'text': 'Effects of Alcohol Abuse on the Brain  A small amount (up to 10%) of the liver acetaldehyde may  accumulate inside the liver cells. As more alcohol is ingested, this  stimulates the production of acetaldehyde by both the alcohol  dehydrogenase and MEOS systems. As the levels of acetaldehyde  increase inside the liver cells with heavy consumption of alcohol,  some of the acetaldehyde diffuse into the blood circulation. In  circulation, high levels of acetaldehyde cause nausea and vomiting.  Vomiting causes more body dehydration and loss of electrolytes.  If the dehydration becomes severe enough, this can impair brain  function and a person may lose consciousness.  Alcohol can adversely affect nearly every area of the brain. When  BAC rises, the central nervous system is depressed. Alcohol disrupts  the way nerve cells communicate with each other by interfering  with receptors on certain cells. The immediate impact of alcohol  on the brain can be seen in the awkwardly displayed symptoms  of confusion, blurred vision, slurred speech, and other signs of  intoxication. These symptoms will go away once drinking stops,  but abusive alcohol consumption over time can lead to long-lasting  damage to the brain and nervous system. This is because alcohol  and its metabolic byproducts kill brain cells.  Effects of Excessive Alcohol on the Liver  Alcohol stimulates the release of epinephrine from the kidneys.  Epinephrine binds to receptors in the liver cells to stimulate the  release of glucagon from the pancreas. Glucagon and epinephrine  stimulate glycogenolysis in the liver cells. Epinephrine also  stimulates the breakdown of triglycerides and glycerol into free  fatty acids \\xa0in adipose tissue and are released into the bloodstream  and travel to the liver.  Health Consequences of Alcohol Abuse  |  443'},\n",
       " {'page_number': 152,\n",
       "  'page_char_count': 1226,\n",
       "  'page_word_count': 208,\n",
       "  'page_sentence_count_raw': 8,\n",
       "  'page_token_count': 306.5,\n",
       "  'text': 'Image by  Allison  Calabrese /  CC BY 4.0  and negatively charged electrolytes are called anions. For example,  in water sodium chloride (the chemical name for table salt)  dissociates into sodium cations (Na+) and chloride anions (Cl−).  Solutes refers to all dissolved substances in a fluid, which may  be charged, such as sodium (Na+), or uncharged, such as glucose.  In the human body, water and solutes are distributed into two  compartments: inside cells, called intracellular, and outside cells,  called extracellular. The extracellular water compartment is  subdivided into the spaces between cells also known as interstitial,  blood plasma, and other bodily fluids such as the cerebrospinal fluid  which surrounds and protects the brain and spinal cord (Figure 3.2  “Distribution of Body Water”). The composition of solutes differs  between the fluid compartments. For instance, more protein is  inside cells than outside and more chloride anions exist outside of  cells than inside.  Figure 3.2 Distribution of Body Water  Osmoregulation  One of the essential homeostatic functions of the body is to  maintain fluid balance and the differences in solute composition  152  |  Overview of Fluid and Electrolyte Balance'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.sample(pages_and_texts, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-41</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7.25</td>\n",
       "      <td>Human Nutrition: 2020 Edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-39</td>\n",
       "      <td>320</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>80.00</td>\n",
       "      <td>Human Nutrition: 2020  Edition  UNIVERSITY OF ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-38</td>\n",
       "      <td>212</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>53.00</td>\n",
       "      <td>Human Nutrition: 2020 Edition by University of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-37</td>\n",
       "      <td>797</td>\n",
       "      <td>145</td>\n",
       "      <td>2</td>\n",
       "      <td>199.25</td>\n",
       "      <td>Contents  Preface  University of Hawai‘i at Mā...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "0          -41               29                4                        1   \n",
       "1          -40                0                1                        1   \n",
       "2          -39              320               54                        1   \n",
       "3          -38              212               32                        1   \n",
       "4          -37              797              145                        2   \n",
       "\n",
       "   page_token_count                                               text  \n",
       "0              7.25                      Human Nutrition: 2020 Edition  \n",
       "1              0.00                                                     \n",
       "2             80.00  Human Nutrition: 2020  Edition  UNIVERSITY OF ...  \n",
       "3             53.00  Human Nutrition: 2020 Edition by University of...  \n",
       "4            199.25  Contents  Preface  University of Hawai‘i at Mā...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1148.00</td>\n",
       "      <td>198.30</td>\n",
       "      <td>9.97</td>\n",
       "      <td>287.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.86</td>\n",
       "      <td>560.38</td>\n",
       "      <td>95.76</td>\n",
       "      <td>6.19</td>\n",
       "      <td>140.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.75</td>\n",
       "      <td>762.00</td>\n",
       "      <td>134.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>190.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1231.50</td>\n",
       "      <td>214.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>307.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25</td>\n",
       "      <td>1603.50</td>\n",
       "      <td>271.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>400.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>2308.00</td>\n",
       "      <td>429.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>577.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count      1208.00          1208.00          1208.00                  1208.00   \n",
       "mean        562.50          1148.00           198.30                     9.97   \n",
       "std         348.86           560.38            95.76                     6.19   \n",
       "min         -41.00             0.00             1.00                     1.00   \n",
       "25%         260.75           762.00           134.00                     4.00   \n",
       "50%         562.50          1231.50           214.50                    10.00   \n",
       "75%         864.25          1603.50           271.00                    14.00   \n",
       "max        1166.00          2308.00           429.00                    32.00   \n",
       "\n",
       "       page_token_count  \n",
       "count           1208.00  \n",
       "mean             287.00  \n",
       "std              140.10  \n",
       "min                0.00  \n",
       "25%              190.50  \n",
       "50%              307.88  \n",
       "75%              400.88  \n",
       "max              577.00  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further text processing (splitting pages into sentances)\n",
    "Two ways to do this:\n",
    "\n",
    "1. We've done this by splitting on `. `.\n",
    "2. We can do this with a NLP library such as spaCy and nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This is a sentence., This another sentence., I like elephants.]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "\n",
    "# Add a sentencizer pipeline\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# Create documemt instance as an example.\n",
    "doc = nlp(\"This is a sentence. This another sentence. I like elephants.\")\n",
    "assert len(list(doc.sents)) == 3\n",
    "\n",
    "# Print out our sentences split\n",
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_number': 559,\n",
       " 'page_char_count': 863,\n",
       " 'page_word_count': 136,\n",
       " 'page_sentence_count_raw': 8,\n",
       " 'page_token_count': 215.75,\n",
       " 'text': 'Image by  Allison  Calabrese /  CC BY 4.0  Korsakoff syndrome can cause similar symptoms as beriberi such  as confusion, loss of coordination, vision changes, hallucinations,  and may progress to coma and death. This condition is specific  to alcoholics as diets high in alcohol can cause thiamin deficiency.  Other individuals at risk include individuals who also consume diets  typically low in micronutrients such as those with eating disorders,  elderly, and individuals who have gone through gastric bypass  surgery.5  Figure 9.10 The Role of Thiamin  Figure 9.11 Beriberi, Thiamin Deficiency  5.\\xa0Fact Sheets for Health Professionals: Thiamin. National  Institute of Health, Office of Dietary Supplements.  \\xa0https://ods.od.nih.gov/factsheets/Thiamin- HealthProfessional/. Updated Feburary 11, 2016.  Accessed October 22, 2017.  Water-Soluble Vitamins  |  559'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_texts[600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1208/1208 [00:03<00:00, 320.98it/s]\n"
     ]
    }
   ],
   "source": [
    "for item in tqdm(pages_and_texts):\n",
    "    item['sentences'] = list(nlp(item['text']).sents)\n",
    "\n",
    "    # Make sure all sentences are strings (the default type is spacy datatype)\n",
    "    item['sentences'] = [str(sentence) for sentence in item['sentences']]\n",
    "\n",
    "    # Count the sentences\n",
    "    item['page_sentence_count_spacy'] = len(item['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 631,\n",
       "  'page_char_count': 1458,\n",
       "  'page_word_count': 251,\n",
       "  'page_sentence_count_raw': 10,\n",
       "  'page_token_count': 364.5,\n",
       "  'text': 'Phosphorus  UNIVERSITY OF HAWAI‘I AT MĀNOA FOOD SCIENCE AND HUMAN  NUTRITION PROGRAM AND HUMAN NUTRITION PROGRAM  Phosphorus’s Functional Role  Phosphorus is present in our bodies as part of a chemical group  called a phosphate group. These phosphate groups are essential  as a structural component of cell membranes (as phospholipids),  DNA and RNA, energy production (ATP), and regulation of acid- base homeostasis. Phosphorus however is mostly associated with  calcium as a part of the mineral structure of bones and teeth. \\xa0Blood  phosphorus levels are not controlled as strictly as calcium so the  PTH stimulates renal excretion of phosphate so that it does not  accumulate to toxic levels.  Dietary Reference Intakes for Phosphorus  In comparison to calcium, most Americans are not at risk for having  a phosphate deficiency. Phosphate is present in many foods popular  in the American diet including meat, fish, dairy products, processed  foods, and beverages. Phosphate is added to many foods because it  acts as an emulsifying agent, prevents clumping, improves texture  and taste, and extends shelf-life. The average intake of phosphorus  in US adults ranges between 1,000 and 1,500 milligrams per day,  well above the RDA of 700 milligrams per day. The UL set for  phosphorous is 4,000 milligrams per day for adults and 3,000  milligrams per day for people over age seventy.  Table 10.3 Dietary Reference Intakes for Phosphorus  Phosphorus  |  631',\n",
       "  'sentences': ['Phosphorus  UNIVERSITY OF HAWAI‘I AT MĀNOA FOOD SCIENCE AND HUMAN  NUTRITION PROGRAM AND HUMAN NUTRITION PROGRAM  Phosphorus’s Functional Role  Phosphorus is present in our bodies as part of a chemical group  called a phosphate group.',\n",
       "   'These phosphate groups are essential  as a structural component of cell membranes (as phospholipids),  DNA and RNA, energy production (ATP), and regulation of acid- base homeostasis.',\n",
       "   'Phosphorus however is mostly associated with  calcium as a part of the mineral structure of bones and teeth.',\n",
       "   '\\xa0Blood  phosphorus levels are not controlled as strictly as calcium so the  PTH stimulates renal excretion of phosphate so that it does not  accumulate to toxic levels.',\n",
       "   ' Dietary Reference Intakes for Phosphorus  In comparison to calcium, most Americans are not at risk for having  a phosphate deficiency.',\n",
       "   'Phosphate is present in many foods popular  in the American diet including meat, fish, dairy products, processed  foods, and beverages.',\n",
       "   'Phosphate is added to many foods because it  acts as an emulsifying agent, prevents clumping, improves texture  and taste, and extends shelf-life.',\n",
       "   'The average intake of phosphorus  in US adults ranges between 1,000 and 1,500 milligrams per day,  well above the RDA of 700 milligrams per day.',\n",
       "   'The UL set for  phosphorous is 4,000 milligrams per day for adults and 3,000  milligrams per day for people over age seventy.',\n",
       "   ' Table 10.3 Dietary Reference Intakes for Phosphorus  Phosphorus  |  631'],\n",
       "  'page_sentence_count_spacy': 10}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1148.00</td>\n",
       "      <td>198.30</td>\n",
       "      <td>9.97</td>\n",
       "      <td>287.00</td>\n",
       "      <td>10.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.86</td>\n",
       "      <td>560.38</td>\n",
       "      <td>95.76</td>\n",
       "      <td>6.19</td>\n",
       "      <td>140.10</td>\n",
       "      <td>6.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.75</td>\n",
       "      <td>762.00</td>\n",
       "      <td>134.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>190.50</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1231.50</td>\n",
       "      <td>214.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>307.88</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25</td>\n",
       "      <td>1603.50</td>\n",
       "      <td>271.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>400.88</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>2308.00</td>\n",
       "      <td>429.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>577.00</td>\n",
       "      <td>28.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count      1208.00          1208.00          1208.00                  1208.00   \n",
       "mean        562.50          1148.00           198.30                     9.97   \n",
       "std         348.86           560.38            95.76                     6.19   \n",
       "min         -41.00             0.00             1.00                     1.00   \n",
       "25%         260.75           762.00           134.00                     4.00   \n",
       "50%         562.50          1231.50           214.50                    10.00   \n",
       "75%         864.25          1603.50           271.00                    14.00   \n",
       "max        1166.00          2308.00           429.00                    32.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  \n",
       "count           1208.00                    1208.00  \n",
       "mean             287.00                      10.32  \n",
       "std              140.10                       6.30  \n",
       "min                0.00                       0.00  \n",
       "25%              190.50                       5.00  \n",
       "50%              307.88                      10.00  \n",
       "75%              400.88                      15.00  \n",
       "max              577.00                      28.00  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       " [20, 21, 22, 23, 24]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define split size to turn groups of sentences into chunks\n",
    "num_sentence_chunk_size = 10\n",
    "\n",
    "# Create a funtion to split lists of texts recursively into chunk size\n",
    "# e.g. [20] -> [10, 10] or [25] -> [10, 10, 5]\n",
    "def split_list(input_list: list[str],\n",
    "               splice_size: int=num_sentence_chunk_size) -> list[list[str]]:\n",
    "    return [input_list[i:i+splice_size] for i in range(0, len(input_list), splice_size)]\n",
    "\n",
    "test_list = list(range(25))\n",
    "split_list(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1208/1208 [00:00<00:00, 99886.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loop through pages and texts and split sentences into chunks\n",
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
    "                                         splice_size=num_sentence_chunk_size)\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 837,\n",
       "  'page_char_count': 1854,\n",
       "  'page_word_count': 328,\n",
       "  'page_sentence_count_raw': 21,\n",
       "  'page_token_count': 463.5,\n",
       "  'text': 'Breast Milk  Bottle Formula  Antibodies and lactoferrin in breast  milk protect infants.  Formula does not contain  immunoprotective factors.  The iron in breast milk is absorbed  more easily. Because the iron is bound  to lactoferrin, it is not available for  bacteria in the gut\\xa0 to use as a growth  factor.  Formula contains more iron  than breast milk, but it is not  absorbed as easily, and the iron  is a growth factor for pathogenic  microbes.  The feces that babies produce do not  smell because breastfed infants have  different bacteria in the gut.  The feces that bottle-fed infants  produce tends to have a  foul-smelling odor.  Breast milk is always available and is  always at the correct temperature.  Formula must be prepared,  refrigerated for storage, and  warmed before it is given to an  infant.  Breastfed infants are less likely to  have constipation.  Bottle-fed infants are more  likely to have constipation.  Breastfeeding ostensibly is free,  though purchasing optional supplies  such as a pump and bottles to express  milk does require some expense.  Formula must be purchased and  is expensive, typically costing  over $1,200 in the first year.  Breast milk contains the fatty acids  DHA and EPA, which are vital for brain  and vision development.  Some formulas contain DHA and  EPA.  Source: American Pregnancy Association (2019, October 14).  Breastfeeding  versus  bottle  feeding.  http://www.americanpregnancy.org/firstyearoflife/ breastfeedingandbottle.html  Introducing Solid Foods  Infants should be breastfed or bottle-fed exclusively for the first  six months of life according to the WHO. Foods that are added  in addition to breastmilk are called complementary foods.  Complementary foods should be nutrient dense to provide optimal  nutrition. Complementary foods include baby meats, vegetables,  Infancy  |  837',\n",
       "  'sentences': ['Breast Milk  Bottle Formula  Antibodies and lactoferrin in breast  milk protect infants.',\n",
       "   ' Formula does not contain  immunoprotective factors.',\n",
       "   ' The iron in breast milk is absorbed  more easily.',\n",
       "   'Because the iron is bound  to lactoferrin, it is not available for  bacteria in the gut\\xa0 to use as a growth  factor.',\n",
       "   ' Formula contains more iron  than breast milk, but it is not  absorbed as easily, and the iron  is a growth factor for pathogenic  microbes.',\n",
       "   ' The feces that babies produce do not  smell because breastfed infants have  different bacteria in the gut.',\n",
       "   ' The feces that bottle-fed infants  produce tends to have a  foul-smelling odor.',\n",
       "   ' Breast milk is always available and is  always at the correct temperature.',\n",
       "   ' Formula must be prepared,  refrigerated for storage, and  warmed before it is given to an  infant.',\n",
       "   ' Breastfed infants are less likely to  have constipation.',\n",
       "   ' Bottle-fed infants are more  likely to have constipation.',\n",
       "   ' Breastfeeding ostensibly is free,  though purchasing optional supplies  such as a pump and bottles to express  milk does require some expense.',\n",
       "   ' Formula must be purchased and  is expensive, typically costing  over $1,200 in the first year.',\n",
       "   ' Breast milk contains the fatty acids  DHA and EPA, which are vital for brain  and vision development.',\n",
       "   ' Some formulas contain DHA and  EPA.',\n",
       "   ' Source: American Pregnancy Association (2019, October 14).',\n",
       "   ' Breastfeeding  versus  bottle  feeding.',\n",
       "   ' http://www.americanpregnancy.org/firstyearoflife/ breastfeedingandbottle.html  Introducing Solid Foods  Infants should be breastfed or bottle-fed exclusively for the first  six months of life according to the WHO.',\n",
       "   'Foods that are added  in addition to breastmilk are called complementary foods.',\n",
       "   ' Complementary foods should be nutrient dense to provide optimal  nutrition.',\n",
       "   'Complementary foods include baby meats, vegetables,  Infancy  |  837'],\n",
       "  'page_sentence_count_spacy': 21,\n",
       "  'sentence_chunks': [['Breast Milk  Bottle Formula  Antibodies and lactoferrin in breast  milk protect infants.',\n",
       "    ' Formula does not contain  immunoprotective factors.',\n",
       "    ' The iron in breast milk is absorbed  more easily.',\n",
       "    'Because the iron is bound  to lactoferrin, it is not available for  bacteria in the gut\\xa0 to use as a growth  factor.',\n",
       "    ' Formula contains more iron  than breast milk, but it is not  absorbed as easily, and the iron  is a growth factor for pathogenic  microbes.',\n",
       "    ' The feces that babies produce do not  smell because breastfed infants have  different bacteria in the gut.',\n",
       "    ' The feces that bottle-fed infants  produce tends to have a  foul-smelling odor.',\n",
       "    ' Breast milk is always available and is  always at the correct temperature.',\n",
       "    ' Formula must be prepared,  refrigerated for storage, and  warmed before it is given to an  infant.',\n",
       "    ' Breastfed infants are less likely to  have constipation.'],\n",
       "   [' Bottle-fed infants are more  likely to have constipation.',\n",
       "    ' Breastfeeding ostensibly is free,  though purchasing optional supplies  such as a pump and bottles to express  milk does require some expense.',\n",
       "    ' Formula must be purchased and  is expensive, typically costing  over $1,200 in the first year.',\n",
       "    ' Breast milk contains the fatty acids  DHA and EPA, which are vital for brain  and vision development.',\n",
       "    ' Some formulas contain DHA and  EPA.',\n",
       "    ' Source: American Pregnancy Association (2019, October 14).',\n",
       "    ' Breastfeeding  versus  bottle  feeding.',\n",
       "    ' http://www.americanpregnancy.org/firstyearoflife/ breastfeedingandbottle.html  Introducing Solid Foods  Infants should be breastfed or bottle-fed exclusively for the first  six months of life according to the WHO.',\n",
       "    'Foods that are added  in addition to breastmilk are called complementary foods.',\n",
       "    ' Complementary foods should be nutrient dense to provide optimal  nutrition.'],\n",
       "   ['Complementary foods include baby meats, vegetables,  Infancy  |  837']],\n",
       "  'num_chunks': 3}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1148.00</td>\n",
       "      <td>198.30</td>\n",
       "      <td>9.97</td>\n",
       "      <td>287.00</td>\n",
       "      <td>10.32</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.86</td>\n",
       "      <td>560.38</td>\n",
       "      <td>95.76</td>\n",
       "      <td>6.19</td>\n",
       "      <td>140.10</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.75</td>\n",
       "      <td>762.00</td>\n",
       "      <td>134.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>190.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1231.50</td>\n",
       "      <td>214.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>307.88</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25</td>\n",
       "      <td>1603.50</td>\n",
       "      <td>271.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>400.88</td>\n",
       "      <td>15.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>2308.00</td>\n",
       "      <td>429.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>577.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count      1208.00          1208.00          1208.00                  1208.00   \n",
       "mean        562.50          1148.00           198.30                     9.97   \n",
       "std         348.86           560.38            95.76                     6.19   \n",
       "min         -41.00             0.00             1.00                     1.00   \n",
       "25%         260.75           762.00           134.00                     4.00   \n",
       "50%         562.50          1231.50           214.50                    10.00   \n",
       "75%         864.25          1603.50           271.00                    14.00   \n",
       "max        1166.00          2308.00           429.00                    32.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  num_chunks  \n",
       "count           1208.00                    1208.00     1208.00  \n",
       "mean             287.00                      10.32        1.53  \n",
       "std              140.10                       6.30        0.64  \n",
       "min                0.00                       0.00        0.00  \n",
       "25%              190.50                       5.00        1.00  \n",
       "50%              307.88                      10.00        1.00  \n",
       "75%              400.88                      15.00        2.00  \n",
       "max              577.00                      28.00        3.00  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1208/1208 [00:00<00:00, 17681.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1843"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Split each into its own item\n",
    "pages_and_chunks = []\n",
    "for item in tqdm(pages_and_texts):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = {}\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "\n",
    "        # Join the sentences together into a paragraph like structure, aka join the list of sentences into one paragraph\n",
    "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "        joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # \".A\" => \". A\" (will work for any capital letter)\n",
    "\n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "\n",
    "        # Get some stats on our chunks\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4   # 1 token = ~4 chars\n",
    "\n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "\n",
    "len(pages_and_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 671,\n",
       "  'sentence_chunk': '2003). Zinc deficiency.\\xa0British Medical Journal,\\xa0326(7386), 409–410.doi: 10.1136/ bmj.326.7386.409. Accessed October 2, 2011. http://www.ncbi.nlm.nih.gov/pmc/articles/ PMC1125304/?tool=pmcentrez. Zinc | 671',\n",
       "  'chunk_char_count': 206,\n",
       "  'chunk_word_count': 17,\n",
       "  'chunk_token_count': 51.5}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_chunks, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1843.00</td>\n",
       "      <td>1843.00</td>\n",
       "      <td>1843.00</td>\n",
       "      <td>1843.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>583.38</td>\n",
       "      <td>734.44</td>\n",
       "      <td>112.33</td>\n",
       "      <td>183.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>347.79</td>\n",
       "      <td>447.54</td>\n",
       "      <td>71.22</td>\n",
       "      <td>111.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>280.50</td>\n",
       "      <td>315.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>78.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>586.00</td>\n",
       "      <td>746.00</td>\n",
       "      <td>114.00</td>\n",
       "      <td>186.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>890.00</td>\n",
       "      <td>1118.50</td>\n",
       "      <td>173.00</td>\n",
       "      <td>279.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>1831.00</td>\n",
       "      <td>297.00</td>\n",
       "      <td>457.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count      1843.00           1843.00           1843.00            1843.00\n",
       "mean        583.38            734.44            112.33             183.61\n",
       "std         347.79            447.54             71.22             111.89\n",
       "min         -41.00             12.00              3.00               3.00\n",
       "25%         280.50            315.00             44.00              78.75\n",
       "50%         586.00            746.00            114.00             186.50\n",
       "75%         890.00           1118.50            173.00             279.62\n",
       "max        1166.00           1831.00            297.00             457.75"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_chunks)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-41</td>\n",
       "      <td>Human Nutrition: 2020 Edition</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>7.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-39</td>\n",
       "      <td>Human Nutrition: 2020 Edition UNIVERSITY OF HA...</td>\n",
       "      <td>308</td>\n",
       "      <td>42</td>\n",
       "      <td>77.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-38</td>\n",
       "      <td>Human Nutrition: 2020 Edition by University of...</td>\n",
       "      <td>210</td>\n",
       "      <td>30</td>\n",
       "      <td>52.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-37</td>\n",
       "      <td>Contents Preface University of Hawai‘i at Māno...</td>\n",
       "      <td>766</td>\n",
       "      <td>114</td>\n",
       "      <td>191.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-36</td>\n",
       "      <td>Lifestyles and Nutrition University of Hawai‘i...</td>\n",
       "      <td>941</td>\n",
       "      <td>142</td>\n",
       "      <td>235.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                     sentence_chunk  \\\n",
       "0          -41                      Human Nutrition: 2020 Edition   \n",
       "1          -39  Human Nutrition: 2020 Edition UNIVERSITY OF HA...   \n",
       "2          -38  Human Nutrition: 2020 Edition by University of...   \n",
       "3          -37  Contents Preface University of Hawai‘i at Māno...   \n",
       "4          -36  Lifestyles and Nutrition University of Hawai‘i...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  \n",
       "0                29                 4               7.25  \n",
       "1               308                42              77.00  \n",
       "2               210                30              52.50  \n",
       "3               766               114             191.50  \n",
       "4               941               142             235.25  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter chunks of text for short chunks\n",
    "\n",
    "These chunks may not contain much useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk token count: 24.25 | Text: These activities are available in the web-based textbook and not available in the Magnesium | 643\n",
      "Chunk token count: 16.5 | Text: Table 4.6 Sweeteners Carbohydrates and Personal Diet Choices | 281\n",
      "Chunk token count: 11.25 | Text: Accessed March 17, 2011. 212 | Water Concerns\n",
      "Chunk token count: 28.75 | Text: Bouayed, J. and T. Bohn. (2010). Exogenous Antioxidants—Double-Edged Swords in Cellular Redox MyPlate Planner | 753\n",
      "Chunk token count: 13.25 | Text: https://doi.org/10.1186/ 1743-7075-4-24. Sulfur | 637\n"
     ]
    }
   ],
   "source": [
    "# Show random chunks with under 30 tokens in length\n",
    "min_token_length = 30\n",
    "for row in df[df[\"chunk_token_count\"] <= min_token_length].sample(5).iterrows():\n",
    "    print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_chunk\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': -39,\n",
       "  'sentence_chunk': 'Human Nutrition: 2020 Edition UNIVERSITY OF HAWAI‘I AT MĀNOA FOOD SCIENCE AND HUMAN NUTRITION PROGRAM ALAN TITCHENAL, SKYLAR HARA, NOEMI ARCEO CAACBAY, WILLIAM MEINKE-LAU, YA-YUN YANG, MARIE KAINOA FIALKOWSKI REVILLA, JENNIFER DRAPER, GEMADY LANGFELDER, CHERYL GIBBY, CHYNA NICOLE CHUN, AND ALLISON CALABRESE',\n",
       "  'chunk_char_count': 308,\n",
       "  'chunk_word_count': 42,\n",
       "  'chunk_token_count': 77.0},\n",
       " {'page_number': -38,\n",
       "  'sentence_chunk': 'Human Nutrition: 2020 Edition by University of Hawai‘i at Mānoa Food Science and Human Nutrition Program is licensed under a Creative Commons Attribution 4.0 International License, except where otherwise noted.',\n",
       "  'chunk_char_count': 210,\n",
       "  'chunk_word_count': 30,\n",
       "  'chunk_token_count': 52.5}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out dataframe for rows with under 30 tokens\n",
    "pages_and_chunks_over_min_token_len = df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient=\"records\")\n",
    "pages_and_chunks_over_min_token_len[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 1073,\n",
       "  'sentence_chunk': 'Image by Jennifer Draper / CC BY 4.0 Image by CDC / Unsplash License Intuitive Eating Intuitive eating is a non-diet approach to eating that promotes a Calories In Versus Calories Out | 1073',\n",
       "  'chunk_char_count': 190,\n",
       "  'chunk_word_count': 34,\n",
       "  'chunk_token_count': 47.5}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_chunks_over_min_token_len, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 12\u001b[0m\n\u001b[0;32m      7\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe sentence transformer library provides an easy way to create embeddings.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentences can be embedded one by one or in a list.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI like dogs!\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Sentences are encoded/embedded by calling model.encode()\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedding_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m embeddings_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(sentences, embeddings))\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# See the embeddings\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Manish\\udemy_course\\LOCAL_RAG\\localrag_venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:674\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m             all_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray([emb\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m emb \u001b[38;5;129;01min\u001b[39;00m all_embeddings])\n\u001b[0;32m    673\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 674\u001b[0m             all_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43m[\u001b[49m\u001b[43memb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43memb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mall_embeddings\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(all_embeddings, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    676\u001b[0m     all_embeddings \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mfrom_numpy(embedding) \u001b[38;5;28;01mfor\u001b[39;00m embedding \u001b[38;5;129;01min\u001b[39;00m all_embeddings]\n",
      "File \u001b[1;32mc:\\Users\\Manish\\udemy_course\\LOCAL_RAG\\localrag_venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:674\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    672\u001b[0m             all_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray([emb\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m emb \u001b[38;5;129;01min\u001b[39;00m all_embeddings])\n\u001b[0;32m    673\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 674\u001b[0m             all_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray([\u001b[43memb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m emb \u001b[38;5;129;01min\u001b[39;00m all_embeddings])\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(all_embeddings, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    676\u001b[0m     all_embeddings \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mfrom_numpy(embedding) \u001b[38;5;28;01mfor\u001b[39;00m embedding \u001b[38;5;129;01min\u001b[39;00m all_embeddings]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\",\n",
    "                                      device=\"cpu\")\n",
    "\n",
    "\n",
    "# Create a list of sentences\n",
    "sentences = [\"The sentence transformer library provides an easy way to create embeddings.\",\n",
    "             \"Sentences can be embedded one by one or in a list.\",\n",
    "             \"I like dogs!\"]\n",
    "\n",
    "# Sentences are encoded/embedded by calling model.encode()\n",
    "embeddings = embedding_model.encode(sentences)\n",
    "embeddings_dict = dict(zip(sentences, embeddings))\n",
    "\n",
    "# See the embeddings\n",
    "for sentence, embedding in embeddings_dict.items():\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Embedding: {embedding}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Version: 2.1.3\n",
      "Torch Version: 2.5.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(\"NumPy Version:\", np.__version__)\n",
    "print(\"Torch Version:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall-mpnet-base-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is a test sentence.\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedding generated successfully:\u001b[39m\u001b[38;5;124m\"\u001b[39m, embedding)\n",
      "File \u001b[1;32mc:\\Users\\Manish\\udemy_course\\LOCAL_RAG\\localrag_venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:674\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m             all_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray([emb\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m emb \u001b[38;5;129;01min\u001b[39;00m all_embeddings])\n\u001b[0;32m    673\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 674\u001b[0m             all_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43m[\u001b[49m\u001b[43memb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43memb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mall_embeddings\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(all_embeddings, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    676\u001b[0m     all_embeddings \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mfrom_numpy(embedding) \u001b[38;5;28;01mfor\u001b[39;00m embedding \u001b[38;5;129;01min\u001b[39;00m all_embeddings]\n",
      "File \u001b[1;32mc:\\Users\\Manish\\udemy_course\\LOCAL_RAG\\localrag_venv\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:674\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    672\u001b[0m             all_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray([emb\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m emb \u001b[38;5;129;01min\u001b[39;00m all_embeddings])\n\u001b[0;32m    673\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 674\u001b[0m             all_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray([\u001b[43memb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m emb \u001b[38;5;129;01min\u001b[39;00m all_embeddings])\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(all_embeddings, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    676\u001b[0m     all_embeddings \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mfrom_numpy(embedding) \u001b[38;5;28;01mfor\u001b[39;00m embedding \u001b[38;5;129;01min\u001b[39;00m all_embeddings]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\", device=\"cpu\")\n",
    "sentences = [\"This is a test sentence.\"]\n",
    "embedding = model.encode(sentences)\n",
    "print(\"Embedding generated successfully:\", embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
