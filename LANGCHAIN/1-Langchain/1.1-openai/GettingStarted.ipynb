{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    " ## LANGSMITH TRACKING\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"GenAIAPPwithOPENAI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x0000022CC55D1360> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000022CC55D3460> root_client=<openai.OpenAI object at 0x0000022CC1917100> root_async_client=<openai.AsyncOpenAI object at 0x0000022CC55D13C0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input and get response from LLM\n",
    "\n",
    "result = llm.invoke(\"What is generative AI\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a category of artificial intelligence systems designed to generate new content, such as text, images, music, or even entire virtual environments, based on patterns and information learned from existing data. Unlike traditional AI systems that focus on recognizing patterns or making decisions based on input data, generative AI models aim to create novel outputs that are similar to the data they were trained on.\\n\\nKey technologies and approaches in generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs):** These involve two neural networks, a generator and a discriminator, that work against each other. The generator creates new data instances, while the discriminator evaluates them. Through this adversarial process, the generator improves its output to produce more realistic data.\\n\\n2. **Variational Autoencoders (VAEs):** These are used to generate new data by learning the underlying distribution of the input data. VAEs encode input data into a latent space and then decode it back into the original space, allowing for the generation of new data points.\\n\\n3. **Transformer Models:** These include models like GPT (Generative Pre-trained Transformer), which are particularly suited for generating and understanding human language. They are trained on large corpora of text and can generate coherent and contextually relevant text based on a given prompt.\\n\\n4. **Diffusion Models:** These models generate data by gradually transforming simple random noise into complex data distributions, often used in image generation tasks.\\n\\nGenerative AI has a wide range of applications, including content creation, entertainment, design, and even drug discovery. It is a rapidly evolving field, with ongoing research aimed at improving the quality, efficiency, and ethical use of generated content.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 338, 'prompt_tokens': 12, 'total_tokens': 350, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_159d8341cc', 'finish_reason': 'stop', 'logprobs': None} id='run-969ae932-11ac-43d5-828f-0d0c8e2e983d-0' usage_metadata={'input_tokens': 12, 'output_tokens': 338, 'total_tokens': 350, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith is not a widely recognized term or concept as of my last update in October 2023. It could potentially refer to a company, tool, or concept that has emerged after this date, or it might be a niche term used within a specific community or context. If \"langsmith\" refers to a particular technology or company you\\'ve encountered, I recommend checking the latest online sources or official websites for the most accurate and up-to-date information.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 36, 'total_tokens': 126, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_159d8341cc', 'finish_reason': 'stop', 'logprobs': None}, id='run-d251dfc4-f0cf-487b-bd13-01c56f617e34-0', usage_metadata={'input_tokens': 36, 'output_tokens': 90, 'total_tokens': 126, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Chain\n",
    "chain = prompt|llm\n",
    "response = chain.invoke({\"input\", \"Can you tell about langsmith?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmith is a platform or tool that typically refers to services or products related to language processing, including natural language processing (NLP), language learning, or language-related software development. However, without more specific context, itâ€™s difficult to pinpoint exactly what \"LangSmith\" refers to, as it could be a brand, company, or software with a focus on language technologies. If you have more context or details, I could provide a more accurate description.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## stroutput parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt|llm|output_parser\n",
    "\n",
    "response = chain.invoke({\"input\", \"Can you tell about langsmith?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
